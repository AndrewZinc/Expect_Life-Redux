{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f77a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependencies\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "from functools import reduce\n",
    "from itertools import combinations\n",
    "from joblib import Parallel, delayed\n",
    "from pymongo import MongoClient\n",
    "import pymongoarrow as pma\n",
    "from pymongoarrow.api import write\n",
    "import numba\n",
    "from numba.typed import List\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "import hvplot.pandas\n",
    "from matplotlib import pyplot as plt\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Suppress YData profile report generation warnings - no actual problems to resolve.\n",
    "from warnings import simplefilter \n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14229f21-8a36-4a95-be30-f37f45d8a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply latest settings for Pandas\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4914ab1-f2b0-413e-b103-fe2df9834868",
   "metadata": {},
   "source": [
    "### Load data from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51bdb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the config from the .env file\n",
    "load_dotenv()\n",
    "MONGODB_URI = os.environ['MONGODB_URI']\n",
    "\n",
    "# Connect to the database engine\n",
    "client = MongoClient(MONGODB_URI)\n",
    "\n",
    "# connect to the project db\n",
    "db = client['ExpectLifeRedux']\n",
    "\n",
    "# get references to the data collections\n",
    "data1 = db['ELR_Input_Data']\n",
    "data2 = db['Encoded_Gov_Data']\n",
    "data3 = db['Encoded_SSS_Data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018184e0-2afd-4a76-8fae-42b95b75a610",
   "metadata": {},
   "source": [
    "### Create DataFrames, Adjust columns, and set Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the ELR_Data collection\n",
    "combined_df = pd.DataFrame(list(data1.find()))\n",
    "\n",
    "# Create a dataframe from the Gov_Clusters collection\n",
    "gc_df = pd.DataFrame(list(data2.find()))\n",
    "\n",
    "# Create a dataframe from the SSS_Cluster collection\n",
    "sc_df = pd.DataFrame(list(data3.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8abef86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a copy of the original combined dataframe\n",
    "ori_df = combined_df.copy()\n",
    "\n",
    "# Drop the database id data and refresh the index\n",
    "combined_df = combined_df.drop(['_id', 'Country', 'Year'], axis=1)\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "combined_df = combined_df.set_index('Country_Year')\n",
    "combined_df = combined_df.drop(['Gov Type', 'SSS Type'], axis=1)\n",
    "# Sort by index\n",
    "combined_df = combined_df.sort_index()\n",
    "\n",
    "gc_df = gc_df.drop(['_id'], axis=1)\n",
    "gc_df = gc_df.reset_index(drop=True)\n",
    "gc_df = gc_df.set_index('Country_Year')\n",
    "# Sort by index\n",
    "gc_df = gc_df.sort_index()\n",
    "\n",
    "sc_df = sc_df.drop(['_id'], axis=1)\n",
    "sc_df = sc_df.reset_index(drop=True)\n",
    "# Sort by index\n",
    "sc_df = sc_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95669875-e0d5-4e4a-bc5b-5fbfc39f886a",
   "metadata": {},
   "source": [
    "### Scale the numeric data before combining with binary encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ab0b4-29e8-4cbd-88ec-2d052f24095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the column labels so they can be reapplied after data scaling\n",
    "numeric_col_names = combined_df.columns.tolist()\n",
    "\n",
    "# Standardize the data with MaxAbsScaler().\n",
    "scaler = MaxAbsScaler()\n",
    "scaled_nda = scaler.fit_transform(combined_df)\n",
    "\n",
    "# Convert the scaled-encoded data back to a DataFrame (nda = Numpy Data Array)\n",
    "scaled_df = pd.DataFrame(scaled_nda, index=combined_df.index)\n",
    "\n",
    "# Apply the column labels to ensure the data is properly identified\n",
    "scaled_df = scaled_df.set_axis(numeric_col_names, axis=1)\n",
    "scaled_df = scaled_df.sort_index()\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d95d00-fc5a-4abd-b3bf-22a68ffd8b12",
   "metadata": {},
   "source": [
    "### Assemble the complete dataset by merging the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f038f1bb-5a6e-4986-ad1e-0a125e1977b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the cluster DataFrames with the primary data.\n",
    "frames = [scaled_df, gc_df, sc_df]\n",
    "merge_frames_df = reduce(lambda left,right: pd.merge(left,right,how='left',on='Country_Year'),frames)\n",
    "\n",
    "complete_df = merge_frames_df.copy().reset_index(drop=True)\n",
    "complete_df = complete_df.set_index('Country_Year')\n",
    "complete_df = complete_df.sort_index()\n",
    "complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86200281-b82e-4011-b406-b7af7490a072",
   "metadata": {},
   "source": [
    "### Assemble the complete visualization dataset by merging the unscaled numeric and binary encoded frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39bb8b6-e3d6-4280-8f68-68e618f98223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the visualization dataframe\n",
    "frames = [combined_df, gc_df, sc_df]\n",
    "merge_df = reduce(lambda left,right: pd.merge(left,right,how='left',on='Country_Year'),frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a336bc-faeb-4253-afc1-60ce43dc27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_df = merge_df.copy().reset_index(drop=True)\n",
    "viz_df = viz_df.set_index('Country_Year')\n",
    "viz_df = viz_df.sort_index()\n",
    "viz_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b48e54-5797-4705-a916-794f89244b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that generates a profile report and saves it to a file\n",
    "def generate_report(df, config_file, output_file):\n",
    "    profile = ProfileReport(df, config_file=config_file)\n",
    "    profile.to_file(output_file)\n",
    "    print(f\"Report {output_file} generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a00e4-6bd4-4b45-a029-3c6b2ccbdf55",
   "metadata": {},
   "source": [
    "### Determine number of components for PCA ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478eccf5-7a78-4ebc-97fe-bca00fcca885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the viable PCA components for a given dataset\n",
    "def compute_pca(input_data):  \n",
    "    # Fit PCA on actual data\n",
    "    pca_actual = PCA(svd_solver='full').fit(input_data)\n",
    "    \n",
    "    cumulative_variance_ratio = np.cumsum(pca_actual.explained_variance_ratio_)\n",
    "    plt.plot(cumulative_variance_ratio)\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('Cumulative explained variance')\n",
    "    plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89af626-cc4a-455f-b6a4-675528d1c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of appropriate components for PCA (scaled (combined) data)\n",
    "compute_pca(complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f912c2-30eb-490f-887b-4507fa150253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform PCA for the provided data\n",
    "def perform_pca(input_data, name, n_comp):\n",
    "    pca = PCA(n_components=n_comp, random_state=42)\n",
    "    pca_out = pca.fit_transform(input_data)\n",
    "\n",
    "    # Create a DataFrame with the principal components.\n",
    "    columnz =[]\n",
    "\n",
    "    for i in range(1,n_comp+1):\n",
    "        columnz.append(name + '_pc'+str(i))\n",
    "    \n",
    "    out_df = pd.DataFrame(data=pca_out, columns=columnz)\n",
    "\n",
    "    out_df['Country_Year'] = ori_df['Country_Year']\n",
    "    out_df = out_df.reset_index(drop=True)\n",
    "    out_df = out_df.set_index('Country_Year')\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c795a-b94a-4474-829b-abe5edc1a0e3",
   "metadata": {},
   "source": [
    "#### Use the PCA data to guide component number selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0732e98-086e-4a22-9a0e-6f3a21cdf96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on the complete_df.\n",
    "complete_pca_df = perform_pca(complete_df, 'Complete', 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4cd02-dafd-40b0-a594-89b72d5412e6",
   "metadata": {},
   "source": [
    "### Determine the number of (KMedoids) clusters for this complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9543e4-62e6-4546-b84b-f066943f8ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use KMedoids and compute Davies-Bouldin scores, elbow curve, and silhouette scores to determine the optimal number of clusters.\n",
    "def compute_kmedoids_cluster_metrics(data_in, n_clusters):\n",
    "    \"\"\"\n",
    "    Function to compute cluster metrics for a given number of clusters.\n",
    "    This function will be called in parallel.\n",
    "    \"\"\"\n",
    "    # Initialize the clusterer with n_clusters value and random state for reproducibility\n",
    "    clusterer = KMedoids(n_clusters=n_clusters, init='k-medoids++', random_state=42)\n",
    "    cluster_labels = clusterer.fit_predict(data_in)\n",
    "    \n",
    "    # Compute the scores for various metrics\n",
    "    davies_bouldin = davies_bouldin_score(data_in, cluster_labels)\n",
    "    inertia = clusterer.inertia_\n",
    "    silhouette_avg = silhouette_score(data_in, cluster_labels)\n",
    "    \n",
    "    return n_clusters, davies_bouldin, inertia, silhouette_avg\n",
    "    \n",
    "def compute_clusters_parallel(data_in, max_clusters, n_jobs=-1):\n",
    "    # Parallel computation of the cluster metrics for each number of clusters from 2 to max_clusters\n",
    "    parallel = Parallel(n_jobs=n_jobs)\n",
    "    kmedoids_cluster_metrics_list = parallel(delayed(compute_kmedoids_cluster_metrics)(data_in, n_clusters)\n",
    "                                    for n_clusters in range(2, max_clusters + 1))\n",
    "\n",
    "    # Creating a DataFrame to store the clustering metrics\n",
    "    kmedoids_cluster_metrics_df = pd.DataFrame(kmedoids_cluster_metrics_list,\n",
    "                                      columns=['Num_Clusters', 'Davies_Bouldin', 'Inertia', 'Silhouette_Avg'])\n",
    "\n",
    "    return kmedoids_cluster_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c1b70-8412-41d2-839b-994f07ecf620",
   "metadata": {},
   "source": [
    "### Compute KMedoids clusters and metrics for the complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0370c3-fb9a-4356-92c9-1cf6d9bcea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "# Create a DataFrame of the results for further analysis downstream - Compute clusters for the complete dataframe\n",
    "non_pca_kmedoid_cluster_scores_df = compute_clusters_parallel(data_in=complete_df, max_clusters=60, n_jobs=-1)\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f\"KMedoids Clustering Execution in {stop - start:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cdf057-cb08-43df-b27a-8ff10f8f75e8",
   "metadata": {},
   "source": [
    "### Compute KMedoids clusters and metrics for the PCA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d93c6-cb5f-4393-ac1f-d4b2af717816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timing\n",
    "pca_kmedoid_cluster_start = time.perf_counter()\n",
    "\n",
    "# Create a DataFrame of the results for further analysis downstream - Compute clusters for the complete dataframe with PCA\n",
    "pca_kmedoid_cluster_scores_df= compute_clusters_parallel(data_in=complete_pca_df, max_clusters=60, n_jobs=-1)\n",
    "\n",
    "# Stop timing\n",
    "pca_kmedoid_cluster_stop = time.perf_counter()\n",
    "\n",
    "print(f\"PCA KMedoids Clustering Execution in {pca_kmedoid_cluster_stop - pca_kmedoid_cluster_start:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7becd21-1243-4ffe-b608-0044573a79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower scores are better\n",
    "pca_kmedoid_cluster_scores_df.hvplot.scatter(x='Num_Clusters', y='Davies_Bouldin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de83577-fec3-4dd5-9a55-b2ecf2a7da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher scores are better\n",
    "pca_kmedoid_cluster_scores_df.hvplot.scatter(x='Num_Clusters', y='Silhouette_Avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ef6c6-5e40-483d-81ad-f8d7dee6e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "cluster_model = KMedoids(n_clusters=55, init='k-medoids++', random_state=42)\n",
    "\n",
    "# Fit the model and predict labels\n",
    "cluster_model.fit_predict(complete_pca_df)\n",
    "\n",
    "# Add the predicted class columns to the visualization dataset\n",
    "complete_pca_viz_df = viz_df.copy()\n",
    "complete_pca_viz_df['KMedoids Clusters'] = cluster_model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb4a972-e7fe-4ca3-b1d3-d866f4715594",
   "metadata": {},
   "source": [
    "## Principal Feature Analysis ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c2bf07-10e8-4c74-a7db-98a407b85926",
   "metadata": {},
   "source": [
    "#### Define functions to select dataset features that provide relevant information for clustering. \n",
    "##### Only important features are used to compute clusters from the complete (non-pca) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942d4e6-7ad2-4b99-ac0f-8b8fca9d1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Helper function - Custom Mean processing to override limitations of Numba compatibility with Numpy features\n",
    "@numba.jit(nopython=True)\n",
    "def custom_mean(arr):\n",
    "    if arr.ndim == 1:\n",
    "        return arr.mean()\n",
    "    elif arr.ndim == 2:\n",
    "        # For 2D arrays, manually compute the mean of each column.\n",
    "        means = np.zeros(arr.shape[1])\n",
    "        for i in range(arr.shape[1]):\n",
    "            means[i] = arr[:, i].mean()\n",
    "        return means\n",
    "    else:\n",
    "        raise ValueError(\"Invalid array dimensions for custom_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54052f-8069-4a6f-9ba9-b32b80222f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Helper function - Calinski Harbasz Score Calculation\n",
    "def calculate_calinski_harbasz(np_array, labels):\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        c_h = calinski_harabasz_score(np_array, labels)\n",
    "        calinski_harbasz = log_scale_value(c_h)\n",
    "        #print(f'    calinski_harbasz index = {calinski_harbasz}')\n",
    "        return calinski_harbasz\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34286573-3ba9-42cc-86d0-9e23e73f708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Helper function - Davies-Bouldin Score Calculation\n",
    "def calculate_davies_bouldin(np_array, labels):\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        davies_bouldin = davies_bouldin_score(np_array, labels)\n",
    "        #print(f'   davies_bouldin score = {davies_bouldin}')\n",
    "        return davies_bouldin\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131fdb1-e0c3-4534-abd8-641895262dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Helper function - Silhouette Coefficient Calculation\n",
    "def calculate_silhouette(np_array, labels):\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        silhouette_val = silhouette_score(np_array, labels)\n",
    "        #print(f' Silhouette Score = {silhouette_val}')\n",
    "        return silhouette_val\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fad2f8-0256-472a-85e1-5ae23b2a65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Helper function - Scatter Separability Calculation\n",
    "def calculate_scatter_separability(np_array, labels):\n",
    "    \"\"\"\n",
    "    Calculates the Scatter Separability (SSC) between clusters in a NumPy array.\n",
    "\n",
    "    Args:\n",
    "        np_array: The NumPy array containing the data points.\n",
    "        labels: The cluster labels for each data point.\n",
    "\n",
    "    Returns:\n",
    "        The Scatter Separability score (SSC).\n",
    "    \"\"\"\n",
    "    unique_labels = np.unique(labels)\n",
    "    n_features = np_array.shape[1]\n",
    "    overall_mean = custom_mean(np_array)\n",
    "\n",
    "    S_w = np.zeros((n_features, n_features))\n",
    "    S_b = np.zeros((n_features, n_features))\n",
    "\n",
    "    for label in unique_labels:\n",
    "        X_k = np_array[labels == label]\n",
    "        mean_k = custom_mean(X_k)\n",
    "        if mean_k.ndim == 1:\n",
    "            mean_k = mean_k[:, None]  # Ensure mean_k is a column vector\n",
    "        n_k = X_k.shape[0]  # Number of samples in current class\n",
    "        mean_diff = mean_k - overall_mean[:, None]  # Ensure mean_diff is correctly shaped\n",
    "    \n",
    "        S_w_k = np.cov(X_k, rowvar=False, bias=True) * (n_k - 1)  # Compute within-class scatter for class k\n",
    "        S_w += S_w_k\n",
    "    \n",
    "        mean_diff = mean_diff.reshape(-1, 1)  # Reshape mean_diff as column vector if not already\n",
    "        S_b += n_k * np.dot(mean_diff, mean_diff.T)  # Correct outer product computation\n",
    "\n",
    "    # Handle singular S_w by adding a small identity matrix to ensure invertibility\n",
    "    if np.linalg.cond(S_w) > 1e10:\n",
    "        S_w += np.eye(S_w.shape[0]) * 1e-4\n",
    "\n",
    "    ssc = np.trace(np.linalg.inv(S_w).dot(S_b))\n",
    "    final_ssc = log_scale_value(ssc)\n",
    "    #print(f'+ computed SSC - value = {final_ssc} ')\n",
    "    return final_ssc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6d94d-d011-48b5-87f8-f3e7a2ec5b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Helper function - Performs Logarithmic scaling of cluster quality score metrics that have unbounded positive ranges - Numba acceleration\n",
    "@numba.jit(nopython=True)\n",
    "def log_scale_value(value, offset=1):\n",
    "    \"\"\"\n",
    "    Applies a logarithmic scaling to a value.\n",
    "    \n",
    "    Parameters:\n",
    "    - value: The positive metric value to be scaled.\n",
    "    - offset: A small positive value to avoid log(0) when the metric is zero.\n",
    "    - scale_max: An upper limit to scale the logarithmic value to, for normalization.\n",
    "    \n",
    "    Returns:\n",
    "    - scaled_value: The logarithmically scaled value, normalized to the range [0, scale_max].\n",
    "    \"\"\"\n",
    "    # Apply logarithmic scaling\n",
    "    log_scaled_value = np.log(value + offset)\n",
    "    \n",
    "    # TBD, normalize the log-scaled value to a specific range, e.g., [0, scale_max]\n",
    "    # if/when implemented, add \", scale_max=1000\" as a function parameter\n",
    "    \n",
    "    return log_scaled_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52cc396-7659-4138-a334-246467295a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Helper function - Normalization of criterion values to remove bias due to number of clusters - Numba acceleration\n",
    "@numba.jit(nopython=True)\n",
    "def cross_projection_normalization(clustering_medoids, scatter_criteria_score, silhouette_criteria_score, davies_bouldin_score, calinski_harbasz_index):\n",
    "    n_clusters = len(clustering_medoids)\n",
    "    projections = np.zeros((n_clusters, n_clusters))\n",
    "\n",
    "    for j in range(n_clusters):\n",
    "        for k in range(j + 1, n_clusters):\n",
    "            medoid_j = clustering_medoids[j]\n",
    "            medoid_k = clustering_medoids[k]\n",
    "            distance = np.linalg.norm(medoid_j - medoid_k)\n",
    "            projections[j][k] = distance\n",
    "            projections[k][j] = distance\n",
    "\n",
    "   # Check if all distances are zero\n",
    "    if np.all(projections == 0):\n",
    "        #print(\"CNP - All pairwise distances are zero! Cannot compute Normalized Score.\")\n",
    "        return 0 \n",
    "    \n",
    "    # Flatten the array and filter non-zero distances\n",
    "    flat_projections = projections.ravel()\n",
    "    non_zero_projections = flat_projections[flat_projections > 0]\n",
    "    \n",
    "    if non_zero_projections.size == 0:\n",
    "        #print(\"CNP - non_zero_projections is empty. Cannot compute Normalized Score.\")\n",
    "        return 0\n",
    "\n",
    "    # Calculate mean of non-zero distances\n",
    "    mean_projection = np.mean(non_zero_projections)\n",
    "\n",
    "    # Normalizing the criteria scores with the mean of projections\n",
    "    # Adjusting the formula to consider Davies-Bouldin Score. Recall: For Davies-Bouldin, lower is better.\n",
    "    # We add 1 to both the numerator and denominator to ensure it doesn't lead to division by zero or negative values.\n",
    "\n",
    "    # Combined normalization factor incorporates all metrics.\n",
    "    normalization_denominator = (1 + mean_projection + davies_bouldin_score) \n",
    "    normalization_numerator = (1 + scatter_criteria_score + silhouette_criteria_score + calinski_harbasz_index)\n",
    "    normalized_score = normalization_numerator / normalization_denominator\n",
    "\n",
    "    return normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5e799-345e-477d-a30a-d6b7c4a936b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Primary function - calls functions to generate cluster metrics in parallel\n",
    "def score_subset_clusters(subset_array, np_array, cluster_labels, clustering_medoids):\n",
    "    # Define tasks to be executed in parallel\n",
    "    tasks = [delayed(calculate_scatter_separability)(subset_array, cluster_labels),\n",
    "             delayed(calculate_silhouette)(subset_array, cluster_labels),\n",
    "             delayed(calculate_davies_bouldin)(subset_array, cluster_labels),\n",
    "             delayed(calculate_calinski_harbasz)(subset_array, cluster_labels)]\n",
    "    \n",
    "    # Execute tasks in parallel and unpack results\n",
    "    scatter_separability, silhouette_score, davies_bouldin_score, calinski_harbasz_index = Parallel(n_jobs=4)(tasks)\n",
    "    \n",
    "    # Pass the results to the normalization function\n",
    "    normalized_score = cross_projection_normalization(clustering_medoids, scatter_separability, silhouette_score, davies_bouldin_score, calinski_harbasz_index)\n",
    "\n",
    "    return normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd7d156-152b-4a2d-a09c-3d75a0c9002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Primary function - Initializes the clustering algorithm\n",
    "def initialize_clustering_instance(clustering_algorithm, rng, flag):\n",
    "    if flag == 'reverse': # Use vanilla algoritms for reverse-search feature scoring to ensure a consistent comparison\n",
    "        if clustering_algorithm == 'kmedoids':\n",
    "            return KMedoids(n_clusters=2, init='k-medoids++'), 0, 'na', 0, 0\n",
    "        elif clustering_algorithm == 'hdbscan':\n",
    "            return HDBSCAN(store_centers=\"medoid\", n_jobs=-1), 0, 'na', 0, 0\n",
    "    else:\n",
    "        metrics = ['manhattan', 'euclidean', 'chebyshev', 'canberra', 'hamming']  # Available metrics - pick one\n",
    "        if clustering_algorithm == 'kmedoids':\n",
    "            #metrics = ['manhattan', 'euclidean', 'cosine']  # Available metrics - pick one\n",
    "            k_val = rng.integers(2, 10)\n",
    "            metric = rng.choice(metrics)  # Randomly select a metric\n",
    "            return KMedoids(n_clusters=k_val, init='k-medoids++', metric=metric), k_val, metric, 0, 0\n",
    "        elif clustering_algorithm == 'hdbscan':\n",
    "            min_cluster_size = rng.choice([10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150])\n",
    "            min_samples = min_cluster_size + rng.choice([10, 20, 30, 40, 50, 60, 70]) # Higher values force conservative clustering\n",
    "            metric = rng.choice(metrics)  # Randomly select a metric\n",
    "            return HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples, metric=metric, cluster_selection_method='eom', store_centers=\"medoid\", n_jobs=-1), 0, metric, min_cluster_size, min_samples\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported clustering algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413734a-5338-4517-891d-9447d159c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Primary function - Evaluates the subset_array\n",
    "def evaluate_subset(clustering_algorithm, subset_array, np_array, rng, flag):\n",
    "    clustering_instance, k_val, metric, min_cluster_size, min_samples = initialize_clustering_instance(clustering_algorithm, rng, flag)\n",
    "    current_labels = clustering_instance.fit_predict(subset_array)\n",
    "    clustering_medoids = getattr(clustering_instance, 'cluster_centers_', getattr(clustering_instance, 'medoids_', None))\n",
    "    return score_subset_clusters(subset_array, np_array, current_labels, clustering_medoids), k_val, metric, min_cluster_size, min_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10669439-74f2-44c6-95b5-363e66a54f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Primary function - Creates a starter_set from the available_indices\n",
    "def select_starter_set(available_indices, interim_features, starter_set_size, rng):\n",
    "    remaining_indices = list(available_indices - interim_features)\n",
    "    if len(remaining_indices) <= starter_set_size: # Check if there are enough indices to create a full starter_set\n",
    "        return rng.shuffle(remaining_indices), 0\n",
    "    else:\n",
    "        return rng.choice(remaining_indices, starter_set_size, replace=False), 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59bd6d8-3c95-4266-9c89-971c8ac692c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Primary function - Adds a new score and the clustering parameters to the collection\n",
    "def update_best_scores(best_scores, score, feature, k_val, metric, cluster_size, num_samples, interim_features, available_indices):\n",
    "    best_scores['k_val'].append(k_val) # K-Medoids - Track the target k\n",
    "    best_scores['cluster_size'].append(cluster_size) # HDBSCAN - Track the size of the clusters\n",
    "    best_scores['num_samples'].append(num_samples)  # HDBSCAN - Track the number of samples per cluster\n",
    "    best_scores['metric'].append(metric)  # K-Medoids - Track the metric\n",
    "    interim_features.add(feature)\n",
    "    available_indices.remove(feature)\n",
    "    return available_indices, interim_features, best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9399a35d-6a47-45b6-bedd-a25fbf9cd670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Primary function - Score the interim_features as they are removed - determine whether any ore not needed.\n",
    "def evaluate_feature_removal(np_array, clustering_algorithm, current_features, feature_to_remove, rng, flag):\n",
    "    # Remove the specified feature from the current feature set\n",
    "    modified_features = [f for f in current_features if f != feature_to_remove]\n",
    "    \n",
    "    # Subset the np_array to include only the modified feature set\n",
    "    subset_array = np_array[:, modified_features]\n",
    "    \n",
    "    # Evaluate the clustering with the modified feature set\n",
    "    score, _, _, _, _, = evaluate_subset(clustering_algorithm, subset_array, np_array, rng, flag)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0c840-19e5-4daf-ae50-ddab49cb3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Primary function - Evaluate the scored interim_features - remove unneeded if below criteria.\n",
    "def perform_reverse_search(np_array, clustering_algorithm, interim_features, global_best_score, rng):\n",
    "    refined_features = set(interim_features)\n",
    "    features_removed = True  # Flag to track if any features were removed in the last pass\n",
    "    local_best_score = global_best_score  # Initialize local best score with global best score\n",
    "\n",
    "    while features_removed:\n",
    "        features_removed = False  # Reset the flag for the current pass\n",
    "        if len(refined_features) == 2:\n",
    "            print('Need to collect more candidate features - we only have 2 features left.')\n",
    "            return refined_features, local_best_score\n",
    "        else:\n",
    "            test_scores = []  # Store feature removal scores for comparison\n",
    "\n",
    "            # Evaluate feature removal in parallel\n",
    "            test_scores = Parallel(n_jobs=8)(\n",
    "                delayed(evaluate_feature_removal)(np_array, clustering_algorithm, list(refined_features), feature, rng, 'reverse')\n",
    "                for feature in refined_features\n",
    "            )\n",
    "            test_scores = list(zip(refined_features, test_scores))  # Combine feature indices with their scores\n",
    "\n",
    "            candidate_removal, candidate_score = max(test_scores, key=lambda x: x[1])  # Use the key argument of the max() function to specify that we want to find the maximum based on the second element of each tuple in test_scores\n",
    "\n",
    "            print(f'Candidate feature {candidate_removal} generated the top removal score {candidate_score:.4f}')\n",
    "\n",
    "            if candidate_score > local_best_score:  # The score improves with the feature removed and is better than the local best score\n",
    "                refined_features.remove(candidate_removal)\n",
    "                features_removed = True  # Indicate that a feature was removed in this pass\n",
    "                local_best_score = candidate_score  # Update the local best score\n",
    "                print(f'Current best score is {local_best_score}')\n",
    "\n",
    "    return refined_features, local_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6976e6-2b0d-4c92-85f1-126305fd31c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Primary function - Evaluate the available indices - iterate through the collection to identify those that improve scores by removal.\n",
    "def perform_reverse_index_removal(np_array, clustering_algorithm, available_indices, global_removal_score, rng):\n",
    "    indices_removed = True  # Flag to track if any features were removed in the last pass\n",
    "    local_removal_score = global_removal_score\n",
    "    iteration = 0  # Counter to limit the number of indices (10) removed in any single session\n",
    "\n",
    "    while indices_removed:\n",
    "        indices_removed = False  # Reset the flag for the current pass\n",
    "        if len(available_indices) == 2:\n",
    "            print('No index removal possible.')\n",
    "            return available_indices, local_removal_score\n",
    "        else:\n",
    "            test_scores = []  # Store feature removal scores for comparison\n",
    "            iteration += 1\n",
    "\n",
    "            # Evaluate feature removal in parallel\n",
    "            test_scores = Parallel(n_jobs=8)(\n",
    "                delayed(evaluate_feature_removal)(np_array, clustering_algorithm, list(available_indices), feature, rng, 'reverse')\n",
    "                for feature in available_indices\n",
    "            )\n",
    "            test_scores = list(zip(available_indices, test_scores))  # Combine feature indices with their scores\n",
    "\n",
    "            candidate_removal, candidate_score = max(test_scores, key=lambda x: x[1])  # Use the key argument of the max() function to specify that we want to find the maximum based on the second element of each tuple in test_scores\n",
    "\n",
    "            print(f'Candidate feature {candidate_removal} generated the top removal score {candidate_score:.4f}')\n",
    "\n",
    "            if candidate_score > local_removal_score:  # The score improves with the feature removed and is better than the global removal score\n",
    "                available_indices.remove(candidate_removal)\n",
    "                indices_removed = True  # Indicate that an index was removed in this pass\n",
    "                local_removal_score = candidate_score  # Update the global removal score\n",
    "                print(f'Current removal score is {local_removal_score}')\n",
    "\n",
    "            if iteration == 10: # Exit when we complete processing\n",
    "                break\n",
    "\n",
    "    return available_indices, local_removal_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf2dcb5-d550-4c29-92c2-dd40109e6228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Helper function - Shuffles the contents of the feature array during combination evaluation\n",
    "def shuffle_array(array, rng):\n",
    "    # Shuffle the array along the first axis (rows)\n",
    "    shuffled_array = array.copy()\n",
    "    rng.shuffle(shuffled_array, axis=0)\n",
    "    return shuffled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e461c3-8236-48ae-a499-223a7d4caf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Primary function - Evaluates new features alongside the initial collection of important features\n",
    "def evaluate_combinations(np_array, clustering_algorithm, available_indices, refined_features, rng, best_scores, global_best_score):\n",
    "    best_combination_score = global_best_score  # Use the global best score as the starting point\n",
    "    iteration = 0\n",
    "\n",
    "    for _ in range(40):  # Number of iterations to refine the feature set\n",
    "        iteration += 1\n",
    "\n",
    "        # Create a list of features to evaluate\n",
    "        features_to_evaluate = list(available_indices - refined_features)\n",
    "\n",
    "        # Evaluate combination and features in parallel\n",
    "        evaluation_results = Parallel(n_jobs=8)(\n",
    "            delayed(evaluate_subset)(clustering_algorithm, shuffle_array(np_array[:, list(refined_features) + [feature]], rng), np_array, rng, 'na')\n",
    "            for feature in features_to_evaluate\n",
    "        )\n",
    "\n",
    "        for idx, (normalized_score, k_val, metric, cluster_size, num_samples) in enumerate(evaluation_results):\n",
    "            feature = features_to_evaluate[idx]\n",
    "\n",
    "            # Update best combination if necessary\n",
    "            if normalized_score > best_combination_score:\n",
    "                best_combination_score = normalized_score\n",
    "                best_feature = feature\n",
    "                best_clust = cluster_size\n",
    "                best_num_samps = num_samples\n",
    "                best_k = k_val\n",
    "                best_metric = metric\n",
    "\n",
    "                # If a better combination was found, add its feature to refined_features\n",
    "                available_indices, refined_features, best_scores = update_best_scores(best_scores, best_combination_score, best_feature, best_k, best_metric, best_clust, best_num_samps, refined_features, available_indices)\n",
    "                print(f'+++ Feature Number {best_feature} added to refined_features - Best Combination Score = {best_combination_score:.4f} - {len(refined_features)} refined_features found so far...')\n",
    "\n",
    "        if iteration % 10 == 0:\n",
    "            print(f'Iteration {iteration}')\n",
    "        \n",
    "    print(f'Processing completed - Total number of identified features = {len(refined_features)}')\n",
    "\n",
    "    return available_indices, refined_features, best_scores, best_combination_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d60e8-7cb7-4655-a449-1e6a6bada002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Primary function - Select candidate features from the available_indices via starter_sets\n",
    "def select_candidate_features_via_starter_set(np_array, clustering_algorithm, n_features, interim_features, available_indices, best_scores, global_best_score, rng):\n",
    "    best_score = 8\n",
    "    ss_flag = 1  # Initalize the local variable in case this function is entered and the processing is skipped\n",
    "    feature_percent = int(0.1 * n_features)\n",
    "    starter_set_size = feature_percent\n",
    "    k_val, min_cluster_size, min_samples, cluster_size, num_samples, iteration = 0, 0, 0, 0, 0, 0\n",
    "    updated = False\n",
    "    \n",
    "    if global_best_score > best_score: # Test for the larger value and carry it forward.\n",
    "        best_score = global_best_score\n",
    "       \n",
    "    while True:  # Simulate a do-while loop\n",
    "        updated = False # Reset the flag for the next round\n",
    "        starter_set, ss_flag = select_starter_set(available_indices, interim_features, starter_set_size, rng)\n",
    "\n",
    "        # Create a list of features to evaluate\n",
    "        features_to_evaluate = list(available_indices - interim_features - set(starter_set))\n",
    "\n",
    "        # Evaluate features in parallel\n",
    "        evaluation_results = Parallel(n_jobs=8)(\n",
    "            delayed(evaluate_subset)(clustering_algorithm, np_array[:, list(starter_set) + [feature]], np_array, rng, 'na')\n",
    "            for feature in features_to_evaluate\n",
    "        )\n",
    "\n",
    "        for idx, (normalized_score, k_val, metric, cluster_size, num_samples) in enumerate(evaluation_results):\n",
    "            feature = features_to_evaluate[idx]\n",
    "\n",
    "            # Update best feature if necessary\n",
    "            if normalized_score > best_score:\n",
    "                updated = True # Flag indicator that a new candidate important feature has been found.\n",
    "                best_score = normalized_score\n",
    "                best_new_feature = feature\n",
    "                best_clust = cluster_size\n",
    "                best_num_samps = num_samples\n",
    "                best_k = k_val\n",
    "                best_metric = metric\n",
    "                \n",
    "                available_indices, interim_features, best_scores = update_best_scores(best_scores, best_score, best_new_feature, best_k, best_metric, best_clust, best_num_samps, interim_features, available_indices)\n",
    "                print(f'Found a new interim feature: {best_new_feature} - with score = {best_score:.4f} - {len(interim_features)} found so far...')\n",
    "                iteration = 0  # Reset the flag\n",
    "        \n",
    "        if len(interim_features) < feature_percent:\n",
    "            if ss_flag == 0:\n",
    "                print(' Finished processing all available features ... ')\n",
    "                break\n",
    "                \n",
    "        # Check if we need to continue or break out of the loop\n",
    "        if len(interim_features) >= feature_percent and not updated:\n",
    "            break\n",
    "            \n",
    "        # Increment the iteration counter if no new features were found\n",
    "        if not updated:  # We didn't find any interim_features during this iteration.\n",
    "            iteration += 1\n",
    "            if iteration % 10 ==0:\n",
    "                print(f' Iteration {iteration}')\n",
    "            if iteration == 30: # Starter_set feature searching has stalled - Begin working with the features identified so far...\n",
    "                print(' 30 iterations without finding a new interim_feature, so work with the collection so far... ')\n",
    "                break\n",
    "\n",
    "    return available_indices, interim_features, best_scores, best_score, ss_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afefe405-91a6-466e-825f-58af1652ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Main function - Orchestrates the analysis\n",
    "def optimal_feature_clusters(np_array, clustering_algorithm):\n",
    "    rng = default_rng()  # Use numpy's random number generation.\n",
    "    n_features = np_array.shape[1]\n",
    "    available_indices = set(range(n_features))\n",
    "    interim_features = set()\n",
    "    best_scores = {'k_val': [], 'cluster_size': [], 'num_samples': [], 'metric': []}\n",
    "    starter_removal_score = 5  # Separate score required for the different removal processing\n",
    "    placeholder_score = 1 # Placeholder score for first pass into select_candidate_features_via_starter_set\n",
    "\n",
    "    # Start the processing by looking for features that negatively impact scoring - remove them from the set (reducing set size increases processing speed).\n",
    "    print(' Start processing ... ')\n",
    "    available_indices, global_removal_score = perform_reverse_index_removal(np_array, clustering_algorithm, available_indices, starter_removal_score, rng)\n",
    "\n",
    "    available_indices, interim_features, best_scores, best_score, ss_flag = select_candidate_features_via_starter_set(np_array, clustering_algorithm, n_features, interim_features, available_indices, best_scores, placeholder_score, rng)\n",
    "    global_best_score = best_score  # Initialize global best score\n",
    "    updated = True\n",
    "    \n",
    "    while updated and (ss_flag == 1):\n",
    "        print(' Starting reverse-search to refine the interim_features ')\n",
    "        refined_features, new_best_score = perform_reverse_search(np_array, 'kmedoids', interim_features, global_best_score, rng)\n",
    "        global_best_score = max(global_best_score, new_best_score)  # Update global best score if needed\n",
    "        \n",
    "        if len(refined_features) == 2:\n",
    "            print(' Collecting more candidate features... ')\n",
    "            available_indices, refined_features, best_scores, best_score, ss_flag = select_candidate_features_via_starter_set(np_array, clustering_algorithm, n_features, refined_features, available_indices, best_scores, global_best_score, rng)\n",
    "            global_best_score = max(global_best_score, best_score)  # Update global best score if needed\n",
    "        else:\n",
    "            updated = False\n",
    "\n",
    "            # Identify any more of the available_indices that negatively affect scoring - remove them\n",
    "            available_indices, global_removal_score = perform_reverse_index_removal(np_array, clustering_algorithm, available_indices, global_removal_score, rng)\n",
    "\n",
    "            # Try to collect more candidate features, if necessary...\n",
    "            available_indices, refined_features, best_scores, best_score, ss_flag = select_candidate_features_via_starter_set(np_array, clustering_algorithm, n_features, refined_features, available_indices, best_scores, global_best_score, rng)\n",
    "            global_best_score = max(global_best_score, best_score)\n",
    "            \n",
    "            refined_features_after_reverse_search = len(refined_features)\n",
    "            \n",
    "            print(' Starting combination evaluation ')\n",
    "            available_indices, refined_features, best_scores, new_best_score = evaluate_combinations(np_array, clustering_algorithm, available_indices, refined_features, rng, best_scores, global_best_score)\n",
    "            global_best_score = max(global_best_score, new_best_score)  # Update global best score if needed\n",
    "            \n",
    "            if len(refined_features) > refined_features_after_reverse_search:\n",
    "                updated = True\n",
    "                print(' Moving to next iteration... ')\n",
    "            else:\n",
    "                print(' Processing completed. ')\n",
    "\n",
    "    return best_scores['k_val'], best_scores['metric'], refined_features, best_scores['cluster_size'], best_scores['num_samples']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b4c3a-fd1c-4330-8fc6-8bcce04431f8",
   "metadata": {},
   "source": [
    "### Perform PFA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a34f8db-361e-41de-a411-4208e9890670",
   "metadata": {},
   "source": [
    "#### KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c4fd7-6304-4b22-bfa7-0ffb3657bb66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^KMedoids Run 1 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "best_kmedoid_features_run1 = set()\n",
    "\n",
    "complete1_df = complete_df.copy()\n",
    "complete1_np = complete1_df.to_numpy()\n",
    "\n",
    "# Run the experiment using the complete (non-pca) dataframe and identify the clustering algorithm by name.\n",
    "best_k_vals_run1, best_kmetric_run1, best_kmedoid_features_run1, na1, na2 = optimal_feature_clusters(complete1_np, 'kmedoids')\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f' ^^^ RUN #1 --- PFA KMedoids Clustering Execution in {stop - start:0.4f} seconds ^^^ ')\n",
    "print(f' Best k values = {sorted(best_k_vals_run1)}')\n",
    "print(f' Best metric values = {sorted(best_kmetric_run1)}')\n",
    "print(f' best features = {sorted(best_kmedoid_features_run1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3fb7e3-4a66-4647-acd5-f90e3f711a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^KMedoids Run 2 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "best_kmedoid_features_run2 = set()\n",
    "\n",
    "complete2_df = complete_df.copy()\n",
    "complete2_np = complete2_df.to_numpy()\n",
    "\n",
    "# Run the experiment using the complete (non-pca) dataframe and identify the clustering algorithm by name.\n",
    "best_k_vals_run2, best_kmetric_run2, best_kmedoid_features_run2, na1, na2 = optimal_feature_clusters(complete2_np, 'kmedoids')\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f' ^^^ RUN #2 --- PFA KMedoids Clustering Execution in {stop - start:0.4f} seconds ^^^ ')\n",
    "print(f' Best k values = {sorted(best_k_vals_run2)}')\n",
    "print(f' Best metric values = {sorted(best_kmetric_run2)}')\n",
    "print(f' best features = {sorted(best_kmedoid_features_run2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07fa40-b99c-4065-8890-922cbc609839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^KMedoids Run 3 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "best_kmedoid_features_run3 = set()\n",
    "\n",
    "complete3_df = complete_df.copy()\n",
    "complete3_np = complete3_df.to_numpy()\n",
    "\n",
    "# Run the experiment using the complete (non-pca) dataframe and identify the clustering algorithm by name.\n",
    "best_k_vals_run3, best_kmetric_run3, best_kmedoid_features_run3, na1, na2 = optimal_feature_clusters(complete3_np, 'kmedoids')\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f' ^^^ RUN #3 --- PFA KMedoids Clustering Execution in {stop - start:0.4f} seconds ^^^ ')\n",
    "print(f' Best k values = {sorted(best_k_vals_run3)}')\n",
    "print(f' Best metric values = {sorted(best_kmetric_run3)}')\n",
    "print(f' best features = {sorted(best_kmedoid_features_run3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea2f60-8691-422b-823f-87a447ce3de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^KMedoids Run 4 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "best_kmedoid_features_run4 = set()\n",
    "\n",
    "complete4_df = complete_df.copy()\n",
    "complete4_np = complete4_df.to_numpy()\n",
    "\n",
    "# Run the experiment using the complete (non-pca) dataframe and identify the clustering algorithm by name.\n",
    "best_k_vals_run4, best_kmetric_run4, best_kmedoid_features_run4, na1, na2 = optimal_feature_clusters(complete4_np, 'kmedoids')\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f' ^^^ RUN #4 --- PFA KMedoids Clustering Execution in {stop - start:0.4f} seconds ^^^ ')\n",
    "print(f' Best k values = {sorted(best_k_vals_run4)}')\n",
    "print(f' Best metric values = {sorted(best_kmetric_run4)}')\n",
    "print(f' best features = {sorted(best_kmedoid_features_run4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97eb4a-afa0-4f9f-8e0e-ee6abb8cb156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^KMedoids Run 5 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "best_kmedoid_features_run5 = set()\n",
    "\n",
    "complete5_df = complete_df.copy()\n",
    "complete5_np = complete5_df.to_numpy()\n",
    "\n",
    "# Run the experiment using the complete (non-pca) dataframe and identify the clustering algorithm by name.\n",
    "best_k_vals_run5, best_kmetric_run5, best_kmedoid_features_run5, na1, na2 = optimal_feature_clusters(complete5_np, 'kmedoids')\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f' ^^^ RUN #5 --- PFA KMedoids Clustering Execution in {stop - start:0.4f} seconds ^^^ ')\n",
    "print(f' Best k values = {sorted(best_k_vals_run5)}')\n",
    "print(f' Best metric values = {sorted(best_kmetric_run5)}')\n",
    "print(f' best features = {sorted(best_kmedoid_features_run5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae22b35-8d36-4c24-a96f-a1aab320dfae",
   "metadata": {},
   "source": [
    "### Process the collected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23bc1c-91b9-46a3-b0c0-ae2aa02441e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify common k-value and features in the KMedoids output\n",
    "# Combine the run results\n",
    "all_k_values = best_k_vals_run1 + best_k_vals_run2 + best_k_vals_run3 + best_k_vals_run4 + best_k_vals_run5\n",
    "all_kmetric_values = best_kmetric_run1 + best_kmetric_run2 + best_kmetric_run3 + best_kmetric_run4 + best_kmetric_run5\n",
    "all_features = [best_kmedoid_features_run1, best_kmedoid_features_run2, best_kmedoid_features_run3, best_kmedoid_features_run4, best_kmedoid_features_run5]\n",
    "\n",
    "# Count the frequency of the values and pick the maximum in the event of a tie\n",
    "k_counter = Counter(all_k_values)\n",
    "most_common_k_values = k_counter.most_common()  # This gives a list of (k, count) pairs\n",
    "max_count = most_common_k_values[0][1]  # The count of the most frequent k\n",
    "# Filter for ties: get all k values with the count equal to max_count\n",
    "ties = [k for k, count in most_common_k_values if count == max_count]\n",
    "# Select the largest k from the ties\n",
    "selected_k = max(ties)  # Select the largest k from the ties\n",
    "\n",
    "kmetric_counter = Counter(all_kmetric_values)\n",
    "most_common_kmetric = kmetric_counter.most_common(1)[0][0]  # Return the most common metric directly\n",
    "print(f'Most common metric: {most_common_kmetric}')\n",
    "\n",
    "# For features, use set operations to find common and all selected features\n",
    "final_kmedoid_common_features = set.intersection(*all_features)\n",
    "final_kmedoid_combined_features = set.union(*all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e7136-bd8f-464d-a3fb-5e96f4d111ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(final_kmedoid_common_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f659dadb-42cf-45c4-a247-a3e08e27698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(final_kmedoid_combined_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22f7f9b-2888-4f44-8c4b-178e6558b51f",
   "metadata": {},
   "source": [
    "### Perform clustering with the reduced feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d1d8b-dacc-43f1-bfc8-3c506dfa0ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the selected features for the final KMedoids clustering\n",
    "\n",
    "# Add a test for whether there are any common results\n",
    "if final_kmedoid_common_features == set(): # no common features found\n",
    "    print(' No common features - skipping ahead... ')\n",
    "else:\n",
    "    # Create a DataFrame for the best common features\n",
    "    kmedoids_common_df = complete_df.copy()\n",
    "    kmedoids_reduced_common_features_df = kmedoids_common_df.iloc[:,sorted(final_kmedoid_common_features)]\n",
    "    \n",
    "    # Perform clustering on the final set of common features with the common k-value\n",
    "    kmedoids_final_common_model = KMedoids(n_clusters=selected_k, init='k-medoids++', metric=most_common_kmetric, random_state=42)\n",
    "    kmedoids_final_common_labels = kmedoids_final_common_model.fit_predict(kmedoids_reduced_common_features_df)\n",
    "    kmedoids_final_common_cluster_centers = kmedoids_final_common_model.cluster_centers_\n",
    "    \n",
    "    # Create the dataframes for visualization\n",
    "    kmedoids_final_viz_common_features_df = viz_df.copy()\n",
    "    kmedoids_final_reduced_common_features_df = kmedoids_final_viz_common_features_df.iloc[:,sorted(final_kmedoid_common_features)]\n",
    "    kmedoids_final_reduced_common_features_df['KMedoids Clusters'] = kmedoids_final_common_labels\n",
    "    \n",
    "    kmedoids_final_COMMON_complete_features_df = viz_df.copy()\n",
    "    kmedoids_final_COMMON_complete_features_df['KMedoids Clusters'] = kmedoids_final_common_labels\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# Create a DataFrame for the best combined features\n",
    "kmedoids_combined_df = complete_df.copy()\n",
    "kmedoids_reduced_combined_features_df = kmedoids_combined_df.iloc[:,sorted(final_kmedoid_combined_features)]\n",
    "\n",
    "# Perform clustering on the final set of combined features with the common k-value\n",
    "kmedoids_final_combined_model = KMedoids(n_clusters=selected_k, init='k-medoids++', metric=most_common_kmetric, random_state=42)\n",
    "kmedoids_final_combined_labels = kmedoids_final_combined_model.fit_predict(kmedoids_reduced_combined_features_df)\n",
    "kmedoids_final_combined_cluster_centers = kmedoids_final_combined_model.cluster_centers_\n",
    "\n",
    "# Create the dataframes for visualization\n",
    "kmedoids_final_viz_combined_features_df = viz_df.copy()\n",
    "kmedoids_final_reduced_combined_features_df = kmedoids_final_viz_combined_features_df.iloc[:,sorted(final_kmedoid_combined_features)]\n",
    "kmedoids_final_reduced_combined_features_df['KMedoids Clusters'] = kmedoids_final_combined_labels\n",
    "\n",
    "kmedoids_final_COMBINED_complete_features_df = viz_df.copy()\n",
    "kmedoids_final_COMBINED_complete_features_df['KMedoids Clusters'] = kmedoids_final_combined_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9301026-e8cc-4797-a38e-e902ee6e6da7",
   "metadata": {},
   "source": [
    "### Generate final K-Medoids Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8962f17-85de-427a-9c83-9a1ff4b6f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "# Create YData reports to explore the KMedoids feature relationships\n",
    "# DataFrames and configuration for the reports\n",
    "\n",
    "# Add a test for whether there are any common results\n",
    "if final_kmedoid_common_features == set(): # no common features found\n",
    "    print(' No common features')\n",
    "    now = str(time.time_ns()) # Create a timestamp for unique filename sets\n",
    "    reports_info = [\n",
    "        {\n",
    "            'df': kmedoids_final_reduced_combined_features_df,\n",
    "            'config_file': 'config_ELR.yml',\n",
    "            'output_file': 'KMedoids_Final_REDUCED_COMBINED-Features_Report-' + now + '.html'\n",
    "        },\n",
    "        {\n",
    "            'df': kmedoids_final_COMBINED_complete_features_df,\n",
    "            'config_file': 'config_ELR.yml',\n",
    "            'output_file': 'KMedoids_Final_COMPLETE_COMBINED-Features_Report-' + now + '.html'\n",
    "        }\n",
    "    ]\n",
    "else:\n",
    "    now = str(time.time_ns()) # Create a timestamp for unique filename sets\n",
    "    reports_info = [\n",
    "        {\n",
    "            'df': kmedoids_final_reduced_common_features_df,\n",
    "            'config_file': 'config_ELR.yml',\n",
    "            'output_file': 'KMedoids_Final_REDUCED_COMMON-Features_Report-' + now + '.html'\n",
    "        },\n",
    "        {\n",
    "            'df': kmedoids_final_COMMON_complete_features_df,\n",
    "            'config_file': 'config_ELR.yml',\n",
    "            'output_file': 'KMedoids_Final_COMPLETE_COMMON-Features_Report-' + now + '.html'\n",
    "        },\n",
    "        {\n",
    "            'df': kmedoids_final_reduced_combined_features_df,\n",
    "            'config_file': 'config_ELR.yml',\n",
    "            'output_file': 'KMedoids_Final_REDUCED_COMBINED-Features_Report-' + now + '.html'\n",
    "        },\n",
    "        {\n",
    "            'df': kmedoids_final_COMBINED_complete_features_df,\n",
    "            'config_file': 'config_ELR.yml',\n",
    "            'output_file': 'KMedoids_Final_COMPLETE_COMBINED-Features_Report-' + now + '.html'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Use joblib to run the report generations in parallel\n",
    "# n_jobs=-1 uses all available CPUs\n",
    "Parallel(n_jobs=4)(delayed(generate_report)(\n",
    "    info['df'], info['config_file'], info['output_file']) for info in reports_info)\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f' ^^^ Final KMedoids Clustering Report building in {stop - start:0.4f} seconds ^^^ ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c11ed-9958-4afe-92ec-19c4ee96efe3",
   "metadata": {},
   "source": [
    "#### HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d14c35a-530d-4b64-b522-d62b091f3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^HDBSCAN Run 1 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "complete11_df = complete_df.copy()\n",
    "complete11_np = complete11_df.to_numpy()\n",
    "\n",
    "best_hdbscan_features_run1 = set()\n",
    "\n",
    "# Run the experiment using the complete (non-pca) dataframe\n",
    "na1, best_hmetric_run1, best_hdbscan_features_run1, best_cluster_size_run1, best_num_samples_run1 = optimal_feature_clusters(complete11_np, 'hdbscan')\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f' ^^^RUN #1 --- PFA HDBSCAN Clustering Execution in {stop - start:0.4f} seconds ^^^ ')\n",
    "print(f' Best metric values = {sorted(best_hmetric_run1)}')\n",
    "print(f' best features 1 = {sorted(best_hdbscan_features_run1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0cbc11-897d-4960-a7eb-7da8db806d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^HDBSCAN Run 2 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "complete12_df = complete_df.copy()\n",
    "complete12_np = complete12_df.to_numpy()\n",
    "\n",
    "best_hdbscan_features_run2 = set()\n",
    "\n",
    "# Run the experiment using the complete (non-pca) dataframe\n",
    "na1, best_hmetric_run2, best_hdbscan_features_run2, best_cluster_size_run2, best_num_samples_run2 = optimal_feature_clusters(complete12_np, 'hdbscan')\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f' ^^^RUN #2 --- PFA HDBSCAN Clustering Execution in {stop - start:0.4f} seconds ^^^ ')\n",
    "print(f' Best metric values = {sorted(best_hmetric_run2)}')\n",
    "print(f' best features 2 = {sorted(best_hdbscan_features_run2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea4ff63-db44-4438-a75f-40cb769f5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^HDBSCAN Run 3 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "complete13_df = complete_df.copy()\n",
    "complete13_np = complete13_df.to_numpy()\n",
    "\n",
    "best_hdbscan_features_run3 = set()\n",
    "\n",
    "# Run the experiment using the complete (non-pca) dataframe\n",
    "na1, best_hmetric_run3, best_hdbscan_features_run3, best_cluster_size_run3, best_num_samples_run3 = optimal_feature_clusters(complete13_np, 'hdbscan')\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f' ^^^RUN #3 --- PFA HDBSCAN Clustering Execution in {stop - start:0.4f} seconds ^^^ ')\n",
    "print(f' Best metric values = {sorted(best_hmetric_run3)}')\n",
    "print(f' best features 3  = {sorted(best_hdbscan_features_run3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df34786-a3b6-4707-bf72-7e6ac495226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^HDBSCAN Run 4 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "complete14_df = complete_df.copy()\n",
    "complete14_np = complete14_df.to_numpy()\n",
    "\n",
    "best_hdbscan_features_run4 = set()\n",
    "\n",
    "# Run the experiment using the complete (non-pca) dataframe\n",
    "na1, best_hmetric_run4, best_hdbscan_features_run4, best_cluster_size_run4, best_num_samples_run4 = optimal_feature_clusters(complete14_np, 'hdbscan')\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f' ^^^RUN #4 --- PFA HDBSCAN Clustering Execution in {stop - start:0.4f} seconds ^^^ ')\n",
    "print(f' Best metric values = {sorted(best_hmetric_run4)}')\n",
    "print(f' best features 4  = {sorted(best_hdbscan_features_run4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba08b14-f94c-46f8-91c0-02948eae7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^HDBSCAN Run 5 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "complete15_df = complete_df.copy()\n",
    "complete15_np = complete15_df.to_numpy()\n",
    "\n",
    "best_hdbscan_features_run5 = set()\n",
    "\n",
    "# Run the experiment using the complete (non-pca) dataframe\n",
    "na1, best_hmetric_run5, best_hdbscan_features_run5, best_cluster_size_run5, best_num_samples_run5 = optimal_feature_clusters(complete15_np, 'hdbscan')\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f' ^^^RUN #5 --- PFA HDBSCAN Clustering Execution in {stop - start:0.4f} seconds ^^^ ')\n",
    "print(f' Best metric values = {sorted(best_hmetric_run5)}')\n",
    "print(f' best features 5  = {sorted(best_hdbscan_features_run5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aca15f-803b-421e-adbf-34a91db94544",
   "metadata": {},
   "source": [
    "### Process the collected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8177fd-08e4-48f2-af27-ad5be59b89be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify common cluster_size value and features in the HDBSCAN output\n",
    "# Combine the run results\n",
    "all_hmetric_values = best_hmetric_run1 + best_hmetric_run2 + best_hmetric_run3 + best_hmetric_run4 + best_hmetric_run5\n",
    "all_cluster_sizes = best_cluster_size_run1 + best_cluster_size_run2 + best_cluster_size_run3 + best_cluster_size_run4 + best_cluster_size_run5\n",
    "all_num_samples = best_num_samples_run1 + best_num_samples_run2 + best_num_samples_run3 + best_num_samples_run4 + best_num_samples_run5\n",
    "all_features = [best_hdbscan_features_run1, best_hdbscan_features_run2, best_hdbscan_features_run3, best_hdbscan_features_run4, best_hdbscan_features_run5]\n",
    "\n",
    "# Count the frequency of the metric values and pick the most common\n",
    "hmetric_counter = Counter(all_hmetric_values)\n",
    "most_common_hmetric = hmetric_counter.most_common(1)[0][0]  # Return the most common metric directly\n",
    "print(f'Most common metric: {most_common_hmetric}')\n",
    "\n",
    "# Count the frequency of the values and pick the maximum in the event of a tie\n",
    "cluster_size_counter = Counter(all_cluster_sizes)\n",
    "most_common_cluster_size_vals = cluster_size_counter.most_common()    # This gives a list of (cluster_size, count) pairs\n",
    "max_count_c_s = most_common_cluster_size_vals[0][1]  # The count of the most frequent cluster_size\n",
    "cluster_ties = [c_size for c_size, count in most_common_cluster_size_vals if count == max_count_c_s]\n",
    "selected_cluster_size = max(cluster_ties) # We want the largest cluster_size in case of a tie\n",
    "\n",
    "# Count the frequency of the values and pick the maximum in the event of a tie\n",
    "sample_size_counter = Counter(all_num_samples)\n",
    "most_common_sample_size_val = sample_size_counter.most_common()   # This gives a list of (sample_size, count) pairs\n",
    "max_count_sample_size = most_common_sample_size_val[0][1]  # The count of the most frequent sample_size\n",
    "sample_ties = [s_num for s_num, count in most_common_sample_size_val if count == max_count_sample_size]\n",
    "selected_sample_size = max(sample_ties) # We want the largest number of samples (per cluster) in the case of a tie\n",
    "\n",
    "# For features, use set operations to find common and combined sets of selected features\n",
    "final_hdbscan_common_features = set.intersection(*all_features)\n",
    "final_hdbscan_combined_features = set.union(*all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b0cdfa-8707-4f86-a4d3-a14bef6e2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' Final HDBSCAN common features = {final_hdbscan_common_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ad00d-3742-45c0-80e2-16e3b2adf076",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' Final HDBSCAN combined features = {sorted(final_hdbscan_combined_features)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf250ef-ac83-42dc-bd5f-9325474632c5",
   "metadata": {},
   "source": [
    "### Perform clustering with the reduced feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac6ca56-6246-4929-af4d-3c8e3b2c4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a test for whether there are any common results\n",
    "if final_hdbscan_common_features == set(): # no common features found\n",
    "    print(' No common features - skipping ahead... ')\n",
    "else:\n",
    "    # Create a DataFrame for the best common features\n",
    "    hdbscan_common_df = complete_df.copy()\n",
    "    hdbscan_reduced_common_features_df = hdbscan_common_df.iloc[:,sorted(final_hdbscan_common_features)]\n",
    "    \n",
    "    # Perform clustering on the final set of common features with the common cluster_size\n",
    "    hdbscan_final_common_model = HDBSCAN(min_cluster_size=selected_cluster_size, min_samples=selected_sample_size, metric=most_common_hmetric, cluster_selection_method='eom', store_centers=\"medoid\", allow_single_cluster=np.bool_(True), n_jobs=-1)\n",
    "    hdbscan_final_common_labels = hdbscan_final_common_model.fit_predict(hdbscan_reduced_common_features_df)\n",
    "    hdbscan_final_common_cluster_centers = hdbscan_final_common_model.medoids_\n",
    "    \n",
    "    # Create the dataframes for visualization\n",
    "    hdbscan_final_viz_common_features_df = viz_df.copy()\n",
    "    hdbscan_final_reduced_common_features_df = kmedoids_final_viz_common_features_df.iloc[:,sorted(final_hdbscan_common_features)]\n",
    "    hdbscan_final_reduced_common_features_df['HDBSCAN Clusters'] = hdbscan_final_common_labels\n",
    "    \n",
    "    hdbscan_final_COMMON_complete_features_df = viz_df.copy()\n",
    "    hdbscan_final_COMMON_complete_features_df['HDBSCAN Clusters'] = hdbscan_final_common_labels\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# Create a DataFrame for the best combined features\n",
    "hdbscan_combined_df = complete_df.copy()\n",
    "hdbscan_reduced_combined_features_df = hdbscan_combined_df.iloc[:,sorted(final_hdbscan_combined_features)]\n",
    "\n",
    "# Perform clustering on the final set of combined features with the common cluster_size\n",
    "hdbscan_final_combined_model = HDBSCAN(min_cluster_size=selected_cluster_size, min_samples=selected_sample_size, metric=most_common_hmetric, cluster_selection_method='eom', store_centers=\"medoid\", allow_single_cluster=np.bool_(True), n_jobs=-1)\n",
    "hdbscan_final_combined_labels = hdbscan_final_combined_model.fit_predict(hdbscan_reduced_combined_features_df)\n",
    "hdbscan_final_combined_cluster_centers = hdbscan_final_combined_model.medoids_\n",
    "\n",
    "# Create the dataframes for visualization\n",
    "hdbscan_final_viz_combined_features_df = viz_df.copy()\n",
    "hdbscan_final_reduced_combined_features_df = hdbscan_final_viz_combined_features_df.iloc[:,sorted(final_hdbscan_combined_features)]\n",
    "hdbscan_final_reduced_combined_features_df['HDBSCAN Clusters'] = hdbscan_final_combined_labels\n",
    "\n",
    "hdbscan_final_COMBINED_complete_features_df = viz_df.copy()\n",
    "hdbscan_final_COMBINED_complete_features_df['HDBSCAN Clusters'] = hdbscan_final_combined_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71262018-b628-4e22-a62c-bde1ac74b06c",
   "metadata": {},
   "source": [
    "### Generate reports to explore the clustering results (reduced feature set & complete feature set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa49a0b-3f95-48c1-bdb8-71595170b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start = time.perf_counter()\n",
    "\n",
    "# Create YData reports to explore the HDBSCAN feature relationships\n",
    "# DataFrames and configuration for the reports\n",
    "\n",
    "if final_hdbscan_common_features == set(): # no common features found\n",
    "    print(' No common features ... ')\n",
    "    now = str(time.time_ns()) # Create a timestamp for unique filename sets\n",
    "    reports_info = [\n",
    "        {\n",
    "            'df': hdbscan_final_reduced_combined_features_df,\n",
    "            'config_file': 'config_ELR.yml',\n",
    "            'output_file': 'HDBSCAN_Final_REDUCED_COMBINED-Features_Report-' + now + '.html'\n",
    "        },\n",
    "        {\n",
    "            'df': hdbscan_final_COMBINED_complete_features_df,\n",
    "            'config_file': 'config_ELR.yml',\n",
    "            'output_file': 'HDBSCAN_Final_COMPLETE_COMBINED-Features_Report-' + now + '.html'\n",
    "        }\n",
    "    ]\n",
    "else:\n",
    "    now = str(time.time_ns()) # Create a timestamp for unique filename sets\n",
    "    reports_info = [\n",
    "        {\n",
    "            'df': hdbscan_final_reduced_common_features_df,\n",
    "            'config_file': 'config_ELR.yml',\n",
    "            'output_file': 'HDBSCAN_Final_REDUCED_COMMON-Features_Report-' + now + '.html'\n",
    "        },\n",
    "        {\n",
    "            'df': hdbscan_final_COMMON_complete_features_df,\n",
    "            'config_file': 'config_ELR.yml',\n",
    "            'output_file': 'HDBSCAN_Final_COMPLETE_COMMON-Features_Report-' + now + '.html'\n",
    "        },\n",
    "        {\n",
    "            'df': hdbscan_final_reduced_combined_features_df,\n",
    "            'config_file': 'config_ELR.yml',\n",
    "            'output_file': 'HDBSCAN_Final_REDUCED_COMBINED-Features_Report-' + now + '.html'\n",
    "        },\n",
    "        {\n",
    "            'df': hdbscan_final_COMBINED_complete_features_df,\n",
    "            'config_file': 'config_ELR.yml',\n",
    "            'output_file': 'HDBSCAN_Final_COMPLETE_COMBINED-Features_Report-' + now + '.html'\n",
    "        }\n",
    "    ]\n",
    "# Use joblib to run the report generations in parallel\n",
    "# n_jobs=-1 uses all available CPUs\n",
    "Parallel(n_jobs=4)(delayed(generate_report)(\n",
    "    info['df'], info['config_file'], info['output_file']) for info in reports_info)\n",
    "\n",
    "# Stop timing\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f\" ^^^ Final HDBSCAN Clustering Report building in {stop - start:0.4f} seconds ^^^ \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32878a-bb2c-4a67-931c-571830cf6ce8",
   "metadata": {},
   "source": [
    "### Write Results to Project Database ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the config from the .env file\n",
    "load_dotenv()\n",
    "MONGODB_URI = os.environ['MONGODB_URI']\n",
    "\n",
    "# Connect to the database engine\n",
    "client = MongoClient(MONGODB_URI)\n",
    "\n",
    "# connect to the project db\n",
    "db = client['ExpectLifeRedux']\n",
    "\n",
    "# get a reference to the data collection\n",
    "#gov_data = db['Encoded_Gov_Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da1475-8efb-4aa2-b466-85c3376357af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefered method - use PyMongoArrow - write the dataframes to the database\n",
    "write(db.Cluster_Unscaled_Complete, viz_df)\n",
    "write(db.Cluster_Scaled_Complete, complete_df)\n",
    "write(db.Cluster_PCA_Complete, complete_pca_df)\n",
    "write(db.Cluster_KMedoids_Reduced_Features, kmedoids_final_reduced_features_df)\n",
    "write(db.Cluster_KMedoids_Complete_Features, kmedoids_final_complete_features_df)\n",
    "write(db.Cluster_HDBSCAN_Reduced_Features, hdbscan_final_reduced_features_df)\n",
    "write(db.Cluster_HDBSCAN_Complete_Features, hdbscan_final_complete_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7d096-879d-41f1-8766-20b3d3f0332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmedoids_cluster_centers_df = pd.DataFrame(kmedoids_final_cluster_centers)\n",
    "#write(db.Cluster_KMedoids_Centers, kmedoids_cluster_centers_df)\n",
    "\n",
    "# Create the dataframe\n",
    "#kmedoids_labels_df = pd.DataFrame(kmedoids_final_labels)\n",
    "#write(db.Cluster_KMedoids_Labels, kmedoids_labels_df)\n",
    "\n",
    "# Create the dataframe\n",
    "#hdbscan_centers_df = pd.DataFrame(hdbscan_final_cluster_centers)\n",
    "#write(db.Cluster_HDBSCAN_Centers, hdbscan_centers_df)\n",
    "\n",
    "# Create the dataframe\n",
    "#hdbscan_labels_df = pd.DataFrame(hdbscan_final_labels)\n",
    "#write(db.Cluster_HDBSCAN_Labels, hdbscan_labels_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c8c48d-5316-4a72-b570-52a0e8d5f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmedoids_best_features_df = pd.DataFrame()\n",
    "kmedoids_best_features_df['Features'] = best_kmedoid_features\n",
    "kmedoids_best_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502e8e8f-1ddb-4ee5-883d-45049831782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbdbscan_best_features_df = pd.DataFrame()\n",
    "hbdbscan_best_features_df['Features'] = best_hdbscan_features\n",
    "hbdbscan_best_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603704b6-bded-4600-987d-549c94f9898a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
